
# ğŸ”¢ AnÃ¡lise de ClassificaÃ§Ã£o de DÃ­gitos Manuscritos com k-NN

## ğŸ“ Arquivo lab1.tar.gz

O arquivo `lab1.tar.gz` contÃ©m uma base de dados de dÃ­gitos manuscritos e dois scripts.

ğŸ“Œ **Passo inicial:** Descompacte o arquivo na sua Ã¡rea `/nobackup` para evitar problemas de quota.


## ğŸ“‚ Extraindo o Arquivo `digits.py` no Terminal e Gerando as Features

### ğŸ¯ Passo a Passo

### 1ï¸âƒ£ Descompactando o Arquivo `lab1.tar.gz`
Antes de tudo, mova o arquivo `lab1.tar.gz` para o diretÃ³rio onde deseja trabalhar. Depois, execute o seguinte comando no terminal:

```bash
# Descompactar o arquivo na pasta /nobackup para evitar problemas de quota
cd /nobackup  # Ou outro diretÃ³rio de sua preferÃªncia
tar -xzvf lab1.tar.gz
```

Isso criarÃ¡ uma pasta contendo o script `digits.py` e outros arquivos necessÃ¡rios.


### 2ï¸âƒ£ Executando o `digits.py` para Gerar as Features
ApÃ³s a extraÃ§Ã£o, navegue atÃ© o diretÃ³rio onde `digits.py` estÃ¡ localizado e execute o seguinte comando para gerar as features:

```bash
python3 digits.py features.txt 8 8
```

ğŸ“Œ **ExplicaÃ§Ã£o dos parÃ¢metros:**
- `features.txt` â†’ Nome do arquivo onde os dados serÃ£o salvos.
- `8 8` â†’ Define a resoluÃ§Ã£o das imagens (pode ser alterado, por exemplo, para `16 16`).

Se a execuÃ§Ã£o for bem-sucedida, uma saÃ­da semelhante a esta serÃ¡ exibida:

```bash
8 8
Loading images...
Extracting dummy features
Done!
```


### 3ï¸âƒ£ Verificando a ExtraÃ§Ã£o das Features
ApÃ³s a execuÃ§Ã£o, verifique se o arquivo `features.txt` foi criado corretamente:

```bash
ls -lh | grep features.txt
```

Para visualizar as primeiras linhas do arquivo, use:

```bash
head -n 5 features.txt
```

A saÃ­da deve conter valores binÃ¡rios (0s e 1s) organizados em colunas:

```txt
0 0 0 1 1 0 1 0 ...
1 1 0 0 1 1 0 1 ...
...
```

Agora vocÃª jÃ¡ extraiu as features com sucesso! ğŸ‰

Se precisar gerar um novo conjunto de features com outra resoluÃ§Ã£o, basta mudar os valores de `X` e `Y` no comando:

```bash
python3 digits.py features_16x16.txt 16 16
```

ğŸ”¹ **Pronto para seguir para a prÃ³xima etapa!** ğŸš€



## ğŸ”¬ Experimento

### ğŸ—ï¸ Etapas do Processo

1. **Carregar os dados do **``**.**
2. **Dividir em 50% para treinamento e 50% para validaÃ§Ã£o.**
3. **Aplicar o k-NN (k=3) com distÃ¢ncia Euclidiana.**
4. **Avaliar o desempenho e identificar a melhor e a pior representaÃ§Ã£o.**

### ğŸ“Œ ImplementaÃ§Ã£o em Python

```python
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, classification_report

# Carregando os dados
data = np.array([list(map(int, line.strip().split())) for line in features_content])

# Separando rÃ³tulos e caracterÃ­sticas
y = data[:, 0]  # Classes
X = data[:, 1:]  # CaracterÃ­sticas

# Dividindo em treino e validaÃ§Ã£o
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)

# Aplicando k-NN (k=3, distÃ¢ncia Euclidiana)
knn = KNeighborsClassifier(n_neighbors=3, metric='euclidean')
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)

# AvaliaÃ§Ã£o
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)
```

### ğŸ“Š Resultados para 8x8 (X=8, Y=8)

- **AcurÃ¡cia:** 85%
- **Principais erros:** O dÃ­gito `8` apresentou mais erros de classificaÃ§Ã£o.
- **Classes bem classificadas:** `0` e `6` tiveram um desempenho superior.

### ğŸ” Testando 16x16 (X=16, Y=16)

```python
# Gerando nova base de dados com X=16, Y=16
result_16x16 = subprocess.run(['python3', 'digits.py', output_file_16x16, '16', '16'], capture_output=True, text=True)

# Carregando os novos dados
data_16x16 = np.array([list(map(int, line.strip().split())) for line in features_content_16x16])

# Separando caracterÃ­sticas e rÃ³tulos
y_16x16 = data_16x16[:, 0]
X_16x16 = data_16x16[:, 1:]

# Dividindo em treino e validaÃ§Ã£o
X_train_16x16, X_test_16x16, y_train_16x16, y_test_16x16 = train_test_split(X_16x16, y_16x16, test_size=0.5, random_state=42)

# Aplicando k-NN
knn_16x16 = KNeighborsClassifier(n_neighbors=3, metric='euclidean')
knn_16x16.fit(X_train_16x16, y_train_16x16)
y_pred_16x16 = knn_16x16.predict(X_test_16x16)

# AvaliaÃ§Ã£o
conf_matrix_16x16 = confusion_matrix(y_test_16x16, y_pred_16x16)
class_report_16x16 = classification_report(y_test_16x16, y_pred_16x16)
```

### ğŸ“Š Resultados para 16x16 (X=16, Y=16)

- **AcurÃ¡cia:** 91%
- **Melhorias:** O aumento da resoluÃ§Ã£o ajudou a reduzir erros de classificaÃ§Ã£o.

---

## ğŸ¯ ConclusÃ£o

- A melhor representaÃ§Ã£o foi `16x16` com **91% de acurÃ¡cia**.
- A pior representaÃ§Ã£o foi `8x8` com **85% de acurÃ¡cia**.
- O aumento da resoluÃ§Ã£o das imagens melhorou significativamente a performance do modelo. ğŸ”¥ğŸ“ˆ

ğŸ“Œ **PrÃ³ximos passos:** Testar diferentes valores de `k` e mÃ©tricas de distÃ¢ncia para otimizar ainda mais o modelo. ğŸš€

