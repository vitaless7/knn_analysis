
# ğŸ”¢ AnÃ¡lise de ClassificaÃ§Ã£o de DÃ­gitos Manuscritos com k-NN

## ğŸ“ Arquivo lab1.tar.gz

O arquivo `lab1.tar.gz` contÃ©m uma base de dados de dÃ­gitos manuscritos e dois scripts.

ğŸ“Œ **Passo inicial:** Descompacte o arquivo na sua Ã¡rea `/nobackup` para evitar problemas de quota.

---

## ğŸ“ ExtraÃ§Ã£o de CaracterÃ­sticas

O script `digits.py` extrai a representaÃ§Ã£o mais simples possÃ­vel de uma base de dados de dÃ­gitos manuscritos:

- Para cada posiÃ§Ã£o da imagem, verifica-se a intensidade do pixel.
- Se o valor for > 128, a caracterÃ­stica Ã© igual a 1; caso contrÃ¡rio, 0.
- Como os classificadores precisam de um vetor de tamanho fixo, as imagens sÃ£o normalizadas utilizando as variÃ¡veis `X` e `Y` dentro da funÃ§Ã£o `rawpixel`.
- ApÃ³s a execuÃ§Ã£o do programa, um arquivo chamado `features.txt` Ã© criado, contendo 2000 linhas no formato:
  ```
  0 0 0 1 1
  ```
  O primeiro nÃºmero indica o rÃ³tulo da classe, seguido pelos valores das caracterÃ­sticas.

---

## ğŸ”¬ Experimento

### ğŸ—ï¸ Etapas do Processo

1. **Carregar os dados do **``**.**
2. **Dividir em 50% para treinamento e 50% para validaÃ§Ã£o.**
3. **Aplicar o k-NN (k=3) com distÃ¢ncia Euclidiana.**
4. **Avaliar o desempenho e identificar a melhor e a pior representaÃ§Ã£o.**

### ğŸ“Œ ImplementaÃ§Ã£o em Python

```python
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, classification_report

# Carregando os dados
data = np.array([list(map(int, line.strip().split())) for line in features_content])

# Separando rÃ³tulos e caracterÃ­sticas
y = data[:, 0]  # Classes
X = data[:, 1:]  # CaracterÃ­sticas

# Dividindo em treino e validaÃ§Ã£o
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)

# Aplicando k-NN (k=3, distÃ¢ncia Euclidiana)
knn = KNeighborsClassifier(n_neighbors=3, metric='euclidean')
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)

# AvaliaÃ§Ã£o
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)
```

### ğŸ“Š Resultados para 8x8 (X=8, Y=8)

- **AcurÃ¡cia:** 85%
- **Principais erros:** O dÃ­gito `8` apresentou mais erros de classificaÃ§Ã£o.
- **Classes bem classificadas:** `0` e `6` tiveram um desempenho superior.

### ğŸ” Testando 16x16 (X=16, Y=16)

```python
# Gerando nova base de dados com X=16, Y=16
result_16x16 = subprocess.run(['python3', 'digits.py', output_file_16x16, '16', '16'], capture_output=True, text=True)

# Carregando os novos dados
data_16x16 = np.array([list(map(int, line.strip().split())) for line in features_content_16x16])

# Separando caracterÃ­sticas e rÃ³tulos
y_16x16 = data_16x16[:, 0]
X_16x16 = data_16x16[:, 1:]

# Dividindo em treino e validaÃ§Ã£o
X_train_16x16, X_test_16x16, y_train_16x16, y_test_16x16 = train_test_split(X_16x16, y_16x16, test_size=0.5, random_state=42)

# Aplicando k-NN
knn_16x16 = KNeighborsClassifier(n_neighbors=3, metric='euclidean')
knn_16x16.fit(X_train_16x16, y_train_16x16)
y_pred_16x16 = knn_16x16.predict(X_test_16x16)

# AvaliaÃ§Ã£o
conf_matrix_16x16 = confusion_matrix(y_test_16x16, y_pred_16x16)
class_report_16x16 = classification_report(y_test_16x16, y_pred_16x16)
```

### ğŸ“Š Resultados para 16x16 (X=16, Y=16)

- **AcurÃ¡cia:** 91%
- **Melhorias:** O aumento da resoluÃ§Ã£o ajudou a reduzir erros de classificaÃ§Ã£o.

---

## ğŸ¯ ConclusÃ£o

- A melhor representaÃ§Ã£o foi `16x16` com **91% de acurÃ¡cia**.
- A pior representaÃ§Ã£o foi `8x8` com **85% de acurÃ¡cia**.
- O aumento da resoluÃ§Ã£o das imagens melhorou significativamente a performance do modelo. ğŸ”¥ğŸ“ˆ

ğŸ“Œ **PrÃ³ximos passos:** Testar diferentes valores de `k` e mÃ©tricas de distÃ¢ncia para otimizar ainda mais o modelo. ğŸš€

